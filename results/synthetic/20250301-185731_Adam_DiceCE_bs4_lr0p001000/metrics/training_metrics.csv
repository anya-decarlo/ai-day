epoch,train_loss,val_loss,dice_score,auroc,auprc,ppv,nne,learning_rate,batch_size,train_samples,val_samples,optimizer_type,loss_function,augmentations,model_architecture,dropout_rate,weight_decay,num_epochs,patch_size,gradient_clipping
1,1.8316033393144608,1.6806676149368287,0.31877389906047265,0.9577344525595032,0.5944056043228871,0.18963833799875526,5.273195338837887,0.001,4,160,40,Adam,DiceCE,Flipping,UNet,0.0,1e-05,30,64,1.0
2,1.6236110597848892,1.564705628156662,0.5109438029174352,0.9799197321610182,0.6703595990509686,0.3434633213671212,2.911519040867597,0.001,4,160,40,Adam,DiceCE,Flipping,UNet,0.0,1e-05,30,64,1.0
3,1.502235358953476,1.4267063438892365,0.6851839833862157,0.9886619216310799,0.7588489104939785,0.5224513820342064,1.9140536983679128,0.001,4,160,40,Adam,DiceCE,Flipping,UNet,0.0,1e-05,30,64,1.0
