Timestamp: 20250301-181428
Model Architecture: UNet
Optimizer: Adam
Loss Function: DiceCE
Initial Learning Rate: 0.001
Batch Size: 4
Epochs: 30
Augmentations: Flipping
Dropout Rate: 0.0
Weight Decay: 1e-05
Patch Size: 64
Gradient Clipping: 1.0
Synthetic Samples: 200
Validation Ratio: 0.2
Agent: RLLRAgent
